%
% 1_prinzip_1d.tex -- Das Prinzip der Methode der finiten Elemente in einer Dimension
%
% (c) 2024 Flurin Brechbühler, OST - Ostschweizer Fachhochschule Rapperswil
%
% !TEX root = ../../buch.tex
% !TEX encoding = UTF-8
%
\section{Prinzip in einer Dimension\label{fem:prinzip_1d}}
\kopfrechts{Prinzip 1D}

Das Vorgehen zum Herleiten der Methode der finiten Elemente kann in fünf Schritte unterteilt werden:
\begin{enumerate}
    \item Bilden der schwachen Form
    \item Diskretisieren
    \item Aufstellen der Matrix
    \item Codieren der Anfangsbedingungen
    \item Lösen des Gleichungssystems bzw. invertieren der Matrix
\end{enumerate}
% TODO: Fünf Schritte durch das Paper ziehen

Um die einzelnen Schritte darzustellen, betrachten wir das Problem
\begin{equation}
    u''(x) = f(x)
    \label{fem:1d:poisson_gleichung},
\end{equation}
was der Poisson-Gleichung entspricht. 
Diese findet in vielen Teilen der Physik Anwendung und ist gleichzeitig ein gutes, einfaches Beispiel einer mit der FEM lösbaren Differenzialgleichung.


\subsection{Bilden der schwachen Form}
Um die Poisson-Gleichung in die schwache Form zu bringen, wird über beide Seiten der Poisson-Gleichung \ref{fem:1d:poisson_gleichung} integriert.
Zuvor werden jedoch beide Seiten mit der Testfunktion $ v(x) $ multipliziert. % TODO: Testfunktion -> Variation
Diese wird definiert als eine beliebige Funktion $ v \colon \mathbb{R} \rightarrow \mathbb{R} $.
Die resultierende Gleichung
\begin{equation}
    \int(u''(x) \cdot v(x) \diff x) = \int(f(x) \cdot v(x) \diff x) \myforall v(x)
    \label{fem:1d:schwache_form}
\end{equation}
sollte einem bekannt vorkommen: Sie entsteht auch beim Herleiten der ersten Variation.
Im Kapitel \ref{buch:variation:section:fundamentallemma} zum Fundamentallemma wird bewiesen, dass die beiden Ausdrücke \ref{fem:1d:poisson_gleichung} und \ref{fem:1d:schwache_form} gleichwertig sind.

Durch partielles Integrieren der linken Seite kann die Ordnung der Differenzialgleichung um eins verringert werden:
\begin{align}
    \int f(x) \cdot v(x) \diff x &= \int u''(x) \cdot v(x) \diff x \\
                                 &= \left. u'(x) \cdot v(x) \right|_{x_1}^{x_2} - \int u'(x) \cdot v'(x) \diff x \\
                                 &= - \int u'(x) \cdot v'(x) \diff x \\
                                 &= - \Phi(u, v)
\end{align}
wobei der Term
\begin{equation}
    \left. u'(x) \cdot v(x) \right|_{x_1}^{x_2}
\end{equation}
Null ist, wenn die Testfunktionen die Randbedingung
\begin{equation}
    v(x_1) = v(x_2) = 0
\end{equation}
erfüllen. % TODO: Hat das nicht implikationen für das Setzen von Randbedingungen?

Der erhaltene Term wird als $-\Phi(u, v)$ abgekürzt.
Dieser Weg kann, abhängig von der ursprünglichen Differenzialgleichung, anders sein.
Das häufigste Vorgehen dabei --- das partielle Ableiten der rechten Seite --- wurde jedoch hier gezeigt.
Ziel ist es, die Ordnung der Differenzialgleichung möglichst stark zu verkleinern, da so Ansätze kleiner Ordnung verwendet werden können.
Dies spart Rechenleistung.


\subsection{Diskretisieren\label{fem:1d:diskretisieren}}
% TODO: Bild zu den Formfunktionen / Approximation einer Fkt. durch diese. 
% TODO: Unterschiedliche Längen delta x
% TODO: Besser schreiben
Um das Problem besser lösbar zu machen, werden die ursprünglichen Funktionen, deren Träger sich in der Regel über den ganzen Wertebereich erstreckt, als Summe einzelner Funktionen mit schmalem Träger 
\begin{equation}
    %TODO: Wiederspruch (PDF Korrektur Hr. Müller) beheben?
    a(x) = \left\{ \begin{array}{ll}
        a(x) = 1            & \text{für} \quad x = 0 \\
        a(x) \in \mathbb{R} & \text{für} \quad 0 < |x| < \Delta x \\
        a(x) = 0            & \text{sonst} 
    \end{array} \right.
\end{equation}
beschrieben:
\begin{equation}
    u(x) \approx \sum_{n=0}^{N}{u_n \cdot a_n(x)} \quad
    \text{und} \quad
    v(x) \approx \sum_{n=0}^{N}{v_n \cdot a_n(x)}
\end{equation}
wobei 
\begin{equation}
    u_n = u(n \cdot \Delta x) \quad
    \text{und} \quad
     v_n = v(n \cdot \Delta x)
\end{equation}
sowie 
\begin{equation}
    a_n(x) = a(x - n \cdot \Delta x).
\end{equation}

Dabei wird die ursprüngliche Funktion an den gleichmässig verteilten Punkten $x_n = n \cdot \Delta x$ abgetastet. 
Die Funktion könnte auch ungleichmässig abgetastet werden, was bei geschickter Wahl der Intervalllänge zu Effizienzverbesserungen führt.
In diesem Paper werden, um die Erklärung möglichst einfach zu halten, nur gleichmässige Intervalle behandelt. 

Für die Interpolationsfunktion $a(x)$ können verschiedene Ansätze gewählt werden:
\begin{itemize}
    \item[\textbf{linear:}] 
        Einfach zu rechnen und zu verstehen, jedoch ist die erste Ableitung unstetig und die zweite Ableitung Null.
        Dementsprechend kann dieser Ansatz nur verwendet werden, wenn keine zweiten Ableitungen im vereinfachten Problem vorkommen.
    \item[\textbf{quadratisch:}]
        Ist die Ordnung des Problems um eins zu hoch, um den linearen Ansatz zu verwenden, kann der quadratische Ansatz eingesetzt werden.
        Die ersten Ableitungen sind jedoch nach wie vor unstetig.
    \item[\textbf{kubisch:}]  
        Der kubische Ansatz hat sehr gute Eigenschaften - er besitzt eine stetige erste Ableitung sowie zweite und dritte Ableitungen ungleich Null. 
        Zudem bietet er die Möglichkeit, die ersten Ableitungen an den Stützpunkten frei zu wählen.
        Dies wird später zum Berücksichtigen der Anfangsbedingungen hilfreich sein.
\end{itemize}

\subsubsection{Linearer Ansatz}
\input{papers/fem/fig/linearer_ansatz.tex} % TODO: Widerholende Formfunktionen und Summe deren als Graphen zeigen
Der lineare Ansatz verwendet die einfachen linearen Funktionen
\begin{equation}
    a(x) = \left\{ \begin{array}{ll}
        1+\frac{x}{\Delta x} & \text{für} \quad -\Delta x < x < 0 \\
        1-\frac{x}{\Delta x} & \text{für} \quad 0 \leq x < \Delta x \\
        0                    & \text{sonst}.
    \end{array} \right.
\end{equation}

Diese Funktionen können mit dem Ansatz 
\begin{equation}
    a(x) = c_1x + c_0 % TODO: Zwei verschiedene a aber keine nicht verwendeten Buchstaben
\end{equation}
und den zu erfüllenden Bedingungen
\begin{equation}
        a(0) = 1 \quad
        \text{und} \quad
        a(-\Delta x) = a(\Delta x) = 0
\end{equation}
hergeleitet werden.

\subsubsection{Quadratischer Ansatz}
\input{papers/fem/fig/quadratischer_ansatz.tex} % TODO: Widerholende Formfunktionen und Summe deren als Graphen zeigen
Der quadratische Ansatz mit den Formfunktionen
\begin{equation}
    a(x) = \left\{ \begin{array}{ll}
        \frac{1}{2(\Delta x)^2} \cdot x^2 + \frac{3}{2 \Delta x} + 1  & \text{für} \quad -2 \Delta x < x < 0 \\
        \frac{1}{2(\Delta x)^2} \cdot x^2 - \frac{3}{2 \Delta x} + 1 & \text{für} \quad 0 \leq x < 2 \Delta x \\
        0                                                             & \text{sonst}
    \end{array} \right.
\end{equation}
für gerade $n$ und
\begin{equation}
    a(x) = \left\{ \begin{array}{ll}
        -\frac{1}{(\Delta x)^2} x^2 + 1 & \text{für} \quad -\Delta x < x < \Delta x \\
        0            & \text{sonst}
    \end{array} \right.
\end{equation}
für ungerade $n$ ist einiges aufwändiger als der lineare Ansatz.

Auch diese Formfunktionen können mit dem Ansatz 
\begin{equation}
    a(x) = c_2x^2 + c_1x + c_0
\end{equation}
und den Bedingungen 
\begin{equation}
        a(0) = 1 \quad
        \text{und} \quad 
        a(-2 \Delta x) = a(-\Delta x) = a(\Delta x) = a(2 \Delta x) = 0
\end{equation}
für gerade $n$ bzw.
\begin{equation}
        a(0) = 1 \quad
        \text{und} \quad
        a(-\Delta x) = a(\Delta x) = 0
\end{equation}
für ungerade $n$ hergeleitet werden.

\subsubsection{Kubischer Ansatz}
\input{papers/fem/fig/kubischer_ansatz.tex} % TODO: Widerholende Formfunktionen und Summe deren als Graphen zeigen
Der kubische Ansatz erbringt die Möglichkeit, den Wert der Funktion wie auch den Wert der Ableitung an den Stützstellen frei zu wählen.
Dafür muss der Ansatz etwas erweitert werden:
\begin{equation}
    u(x) \approx \sum{u_n \cdot a_n(x)} \rightarrow u(x) \approx \sum{u_n \cdot a_n(x) + u'_n \cdot b_n(x)}.
\end{equation}

Die Formfunktionen
\begin{equation}
    a(x) = \left\{ \begin{array}{ll}
        - \frac{2}{(\Delta x)^3} \cdot x^3 + \frac{3}{(\Delta x)^2} \cdot x^2 + 1 
            & \text{für} \quad -\Delta x < x < 0 \\
        \frac{2}{(\Delta x)^3} \cdot x^3 + \frac{3}{(\Delta x)^2} \cdot x^2 + 1 
            & \text{für} \quad 0 \leq x < \Delta x \\
        0
            & \text{sonst}
    \end{array} \right.
\end{equation}
und
\begin{equation}
    b(x) = \left\{ \begin{array}{ll}
        \frac{1}{(\Delta x)^2} \cdot x^3 + \frac{2}{\Delta x} \cdot x^2 + x 
            & \text{für} \quad -\Delta x < x < 0 \\
        \frac{1}{(\Delta x)^2} \cdot x^3 - \frac{2}{\Delta x} \cdot x^2 + x 
            & \text{für} \quad 0 \leq x < \Delta x \\
        0
            & \text{sonst}
    \end{array} \right.
\end{equation}
können ebenfalls mit dem Ansatz
\begin{equation}
    a(x) = c_3x^3 + c_2x^2 + c_1x + c_0 \quad 
    \text{bzw.} \quad
    b(x) = d_3x^3 + d_2x^2 + d_1x + d_0
\end{equation}
und den Bedingungen 
\begin{equation}
        a(0) = 1 \quad
        \text{und} \quad
        a(-\Delta x) = a(\Delta x) = 0 \quad
        \text{sowie} \quad
        a'(-\Delta x) = a'(0) = a'(\Delta x) = 0
\end{equation}
und
\begin{equation}
        b'(0) = 1 \quad
        \text{und} \quad
        b'(-\Delta x) = b'(\Delta x) = 0 \quad
        \text{sowie} \quad
        b(-\Delta x) = b(0) = b(\Delta x) = 0
\end{equation}
hergeleitet werden.


\subsection{Erstellen der Matrix\label{fem:1d:matrix_erstellen}}
Um das Problem als Matrixgleichung zu repräsentieren, muss zunächst die Differenzialgleichung in der schwachen Form in ein lineares Gleichungssystem überführt werden.
Mit den Approximationen 
\begin{align}
    f(x) &\approx \sum_i f_i \cdot a_i(x) \\
    u(x) &\approx \sum_i u_i \cdot a_i(x) \\
    v(x) &\approx \sum_i v_i \cdot a_i(x)
\end{align}
aus der Diskretisierung kann die schwache Form der Differenzialgleichung 
\begin{equation}
    - \int u'(x) \cdot v'(x) \diff x = \int f(x) \cdot v(x) \diff x
\end{equation}
als
\begin{equation}
    - \int \biggl(\sum_i u_j \cdot a'_j(x)\biggr) \biggl(\sum_j v_i \cdot a'_i(x)\biggr) \diff x 
    = \int \biggl(\sum_i f_j \cdot a_j(x) \biggr) \biggl(\sum_j v_i \cdot a_i(x) \biggr) \diff x 
    \myforall v_i
\end{equation}
geschrieben werden.
Die Bedingung $\forall v_i$ ist auch erfüllt, wenn die Summe über $i$ sowie die Multiplikation mit dem beliebigen Faktor $v_i$ weggelassen wird und die resultierende Gleichung für alle $i$ erfüllt sein muss: % TODO: Proof this... Or argue better
\begin{equation}
    - \int \sum_j u_j \cdot a'_j \cdot a'_i(x) \diff x = \int \sum_j f_j \cdot a_j(x) \cdot a_i(x) \diff x \myforall i.
\end{equation}
Dies ermöglicht es, die Summen aus den Integralen zu bringen und die Gleichung als
\begin{equation}
    - \sum_j u_j \int a'_j \cdot a'_i(x) \diff x = \sum_j f_j \int a_j(x) \cdot a_i(x) \diff x \myforall i \label{papers:fem:prinzip1d:finale_gleichung}
\end{equation}
zu schreiben.
Übrig bleibt also, da die Integrale ausgewertet werden können, ein lineares Gleichungssystem mit $N$ Unbekannten $u_j$ und $N$ Gleichungen (eine pro $i$). 

Das erhaltene Gleichungssystem lässt sich nun sehr gut als Matrizen, bei denen die Zeilen über $i$ und die Spalten über $j$ iterieren, darstellen:
\begin{multline}
    \left(
        \begin{matrix}
            \int a'_1(x) \cdot a'_1 \diff x & \hdots & a'_N(x) \cdot a'_1(x) \diff x \\
            \vdots                          & \ddots & \vdots                        \\
            \int a'_1(x) \cdot a'_N \diff x & \hdots & a'_N(x) \cdot a'_N(x) \diff x \\
        \end{matrix}
    \right)
    \left(
        \begin{matrix}
            u_1 \\
            \vdots \\
            u_N
        \end{matrix}
    \right) \\
    = \\
    \left(
        \begin{matrix}
            \int a_1(x) \cdot a_1 \diff x & \hdots & a_N(x) \cdot a_1(x) \diff x \\
            \vdots                        & \ddots & \vdots                      \\
            \int a_1(x) \cdot a_N \diff x & \hdots & a_N(x) \cdot a_N(x) \diff x \\
        \end{matrix}
    \right)
    \left(
        \begin{matrix}
            f_1 \\
            \vdots \\
            f_N
        \end{matrix}
    \right),
\end{multline}
was kompakt als
\begin{equation}
    \mathbf{M}\vec{f} = -\mathbf{L}\vec{u}
\end{equation}
geschrieben wird.
Auch gängig ist das Zusammenfassen von $\mathbf{M}\vec{f}$ zu $\vec{b}$, was zur Gleichung
\begin{equation}
    \mathbf{L}\vec{u} + \vec{b} = 0
\end{equation}
führt.

Diese Matrizen werden aufgrund des schmalen Trägers der Funktionen $a_n(x)$ (sowie $b_n(x)$ beim kubischen Ansatz) sehr schwach besetzt sein, da viele der Integralen
\begin{equation}
    \int a_i(x) \cdot a_j \diff x \quad 
    \text{ bzw. } 
    \quad \int a'_i(x) \cdot a'_j \diff x 
\end{equation}
Null sein werden.
Von null verschieden sind nur die Einträge, deren zugehörige Datenpunkte nebeneinander liegen.
Zudem sind sie symmetrisch und positiv definit, da es keine Rolle spielt in welcher Reihenfolge man die Testfunktionen multipliziert.

\subsubsection{Kubischer Ansatz}
Auch hier verlangt der kubische Ansatz mit seinen zwei Funktionen pro Datenpunkt eine leichte Anpassung: 
\begin{itemize}
    \item Die Vektoren $\vec{b}$ und $\vec{f}$ werden für die gleiche Menge Datenpunkte doppelt so viele Elemente enthalten.
          Dies aus dem Grund, dass für jeden Wert $u_i$ ein zweiter Wert $u'_i$ dazukommt.
    \item Die Matrix $\mathbf{L}$ wird zwangsweise doppelt so viele Zeilen und Spalten enthalten müssen, um mit den neuen Werten rechnen zu können. % TODO: Diese Begrüngung ist noch nicht ganz zufriedenstellend.
\end{itemize}


\subsection{Codieren der Anfangsbedingungen\label{fem:1d:anfangsbedingungen}}
TODO: Erklären, wie Anfangsbedingungen codiert werden können


\subsection{Invertieren der Matrix\label{fem:1d:matrix_invertieren}}
Zur Lösung der Poisson-Gleichung muss nun also "nur" noch die Matrix $\mathbf{L}$ invertiert werden.
Das Resultat in Form des Spaltenvektors $\vec{u}$, enthaltend die Stützstellen der Lösungsfunktion, lässt sich dann als
\begin{equation}
    \vec{u} = - \mathbf{L}^{-1}\mathbf{M}\vec{f} = - \mathbf{L}^{-1}\vec{b}
\end{equation}
berechnen.

Zum Invertieren der Matrix gibt es optimierte Zerlegungsalgorithmen wie SuperLU, Choldmod oder Mumps, die die schwache Besetzung der Matrizen ausnützen, um diese effizient zu zerlegen. % TODO: Maybe cite this.
Nach dem Zerlegen ist das Invertieren stark vereinfacht.
Weiter bieten sich iterative Vorgehen wie die Methode des konjugierten Gradienten oder GMRES an.
Auch diese können aus der schwachen Besetzung der Matrix Nutzen ziehen.

TODO: Sauber recherchieren und referenzieren. Soweit nur Notizen.
