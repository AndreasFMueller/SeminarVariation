%
% 3-oc.tex
%
% (c) 2024 Prof Dr Andreas Müller
%
\section{Optimale Steuerung
\label{buch:hamiltonjacobi:section:oc}}
\kopfrechts{Optimale Steuerung}
Die vorangegangenen Kapitel haben verschiedene Beispiele gezeigt,
in denen Funktionen gesucht waren, für die ein gewisses Integral
einen extremalen Wert annimmt.
In der Praxis tauchen aber auch Probleme auf, in denen die
gesuchte Funktion nicht direkt für die Berechnung des zu minimierenden
Integrals verwendet wird.
Stattdessen fliesst die Funktion in eine Differentialgleichung
ein, deren Lösung dann erst das Funktional ergibt.
Das optimale Steuerungsproblem ist ein Problem dieser Art: gesucht
wird eine Steuerfunktion derart, dass das gesteuerte System, welches
mit einer gewöhnlichen Differentialgleichung beschrieben ist, ein
Kostenfunktional minimieren soll.

In diesem Abschnitt wird die Lösung des optimalen Steuerungsproblem
mit Hilfe des Minimum-Prinzips von Pontryagin skizziert.
In Abschnitt~\ref{buch:hamiltonjacobi:oc:subsection:problem}
wird das Problem exakt formuliert.
Danach wird die Vorgehensweise Anhang eines Variationsproblems
mit Nebenbedingungen motiviert und die zugehörige Hamilton-Funktion
hergeleitet.
In Abschnitt~\ref{buch:hamiltonjacobi:oc:subsection:minimum}
wird dann das Minimum-Prinzip von Pontryagin hergeleitet, mit dem
sich viele dieser Probleme lösen lassen.

%
% Das optimale Steuerungsproblem
%
\subsection{Das optimale Steuerungsproblem
\label{buch:hamiltonjacobi:oc:subsection:problem}}
Ein {\em Steuerungsproblem} für ein System mit Differentialgleichung
der Form
\[
\dot{x}
=
f(t, x, u),
\]
wobei $f\colon\mathbb{R}^n\times\mathbb{R}^m\to\mathbb{R}^n$
eine differenzierbare Funktion ist.
Der Vektor $u$ beeinflusst die Zeitentwicklung der Lösung $x(t)$, man
kann ihn als die Steuersignale betrachten, mit denen man die Lösung
im Rahmen der physikalischen Grenzen des Systems beeinflussen kann.
Durch geeignete Wahl der Funktion $u(t)$ kann man erreichen, dass 
die Lösung mit gewissen Anfangsbedingungen $x(t_0)$ in einem
gewählten Endpunkt $x(t_1)$ endet.

Da man die Zeit ebenfalls als eine Steuervariable auffassen kann, 
kann man die Systemgleichung zu
\begin{equation*}
\dot{x}
=
f(x,u)
\end{equation*}
vereinfachen.
Man darf also annehmen, dass $f$ nicht explizit von der Zeit
abhängt.

%
% Das Kostenfunktional
%
\subsubsection{Das Kostenfunktional}
Wie in früher untersuchten Variationsproblemen können der Funktion $x(t)$
Kosten in Form eines Integrals der Form
\begin{equation}
\int_{t_0}^{t_1}
L(x(t),\dot{x}(t))
\,dt
\label{buch:hamiltonjacobi:oc:eqn:jxdotx}
\end{equation}
zugeordnet werden.
Man kann jetzt fragen, für welche Funktion $u(t)$ die sich daraus
ergebende Bahnkurve $x(t)$ das Funktional
\eqref{buch:hamiltonjacobi:oc:eqn:jx}
minimiert.

In den meisten Fällen umfasst der Zustandsvektor $x(t)$ für die
Systemdifferentialgleichung auch die Geschwindigkeit, so dass
es nicht länger sinnvoll ist, dass die Funktion $L$ auch von
$\dot{x}$ abhängig ist.
Das Funktional wird daher
\begin{equation}
\int_{t_0}^{t_1}
L(x(t))
\,dt
\label{buch:hamiltonjacobi:oc:eqn:jx}
\end{equation}

Dies ist aber noch nicht ganz allgemein genug, denn die Steuerung selbst
ist oft ebenfalls mit Kosten verbunden.
Man denke etwa an die Steuerung einer Rakete, wo jeder Steuerimpuls 
Raketentreibstoff verbraucht, von dem man aus Gewichtsgründen möglichst
wenig mitnehmen möchte.
Die Lagrange-Funktion sollte daher auch noch von $u$ abhängen, die
Kostenfunktion wird daher
\begin{equation}
\int_{t_0}^{t_1}
L(x(t),u(t))
\,dt.
\end{equation}

Doch auch dies ist noch nicht die endgültige Fassung.
In vielen Problemen spielt es eine wichtige Rolle, wann die
Operation abgeschlossen ist.
Zum Beispiel können im späteren Verlauf zusätzliche Kosten entstehen,
wenn die Steuerungsaufgabe erst später abgeschlossen wird.
Erreicht ein Raumschiff die Umlaufbahn einer Raumstation verspätet,
wird zusätzlicher Treibstoff für Orbitalmanöver benötigt, um die Station
zu erreichen.
Wir fügen dem zu minimierenden Funktional daher noch einen Randterm
hinzu und erhalten
\begin{equation}
J(u)
=
\int_{t_0}^{t_1}
L(x(t),u(t))
\,dt
+
K(x(t_1))
\label{buch:hamiltonjacobi:oc:eqn:jk}
\end{equation}
als endgültiges Funktional, welches zu minimieren ist.

%
% Die optimale Steuerungsaufgabe
%
\subsubsection{Die optimale Steuerungsaufgabe}
Damit lässt sich jetzt die Aufgabe formulieren, die in diesem
Abschnitt gelöst werden soll.

\begin{aufgabe}[optimale Steuerung]
\label{buch:hamiltonjacobi:oc:aufgabe}
Für das System mit der Differentialgleichung
\begin{equation}
\dot{x}
=
f(x,u), \qquad f\colon \mathbb{R}^n\times\mathbb{R}^m\to\mathbb{R}^n
\label{buch:hamiltonjacobi:oc:eqn:dgl}
\end{equation}
soll eine Funktion $u\colon [t_0,t_1]\to\mathbb{R}^m$ gefunden werden,
für die 
\begin{equation}
J(u)
=
\int_{t_0}^{t_1}
L(x(t),u(t))
\,dt
+
K(x(t_1))
\label{buch:hamiltonjacobi:oc:eqn:kosten}
\end{equation}
minimiert, wobei $x(t)$ eine Lösung der Differentialgleichung
\eqref{buch:hamiltonjacobi:oc:eqn:dgl} ist, die die Anfangsbedinung
$x(t_0)=x_0$ erfüllt.
\end{aufgabe}

Die Aufgabe verlangt also, eine Steuerfunktion $u(t)$ so zu bestimmen,
dass das System der Bahn $x(t)$ mit minimalen Kosten vom Startpunkt $x_0$
zum Zielpunkt $x_1$ folgt.

%
% Das optimale Steuerungsproblem als Variationsproblem mit Nebenbedingungen
%
\subsubsection{Das optimale Steuerungsproblem als Variationsproblem
mit Nebenbedingungen}
Die Formulierung von Aufgabe~\ref{buch:hamiltonjacobi:oc:aufgabe}
betrachtet die Funktionen $x(t)$ als von $u(t)$ abhängig.
Man muss also erst die
Differentialgleichung~\eqref{buch:hamiltonjacobi:oc:eqn:dgl}
lösen, bevor man das
Kostenfunktional~\eqref{buch:hamiltonjacobi:oc:eqn:kosten}
berechnen kann.
Diese Formulierung macht es unmöglich, die Aufgabe als 
Variationsproblem zu sehen.

Die Aufgabenstellung kann aber auch als Variationsproblem mit
einer Nebenbedingung gesehen werden.
Dazu werden sowohl die Variablen $x$ wie auch die Steuerinputs $u$
als unabhängige Variablen $q=(x,u)$ betrachtet.
Zu bestimmen ist jetzt eine Funktion $q(t)=(x(t),u(t))$, die
das Integral
\[
\int_{t_0}^{t_1}
L(x(t), u(t))
\,dt
\]
minimiert.
Jetzt sieht die Aufgabenstellung wie ein Variationsproblem aus,
allerdings wird damit noch nicht berücksichtigt, dass $x(t)$ eine
Lösung der Differentialgleichung~\eqref{buch:hamiltonjacobi:oc:eqn:dgl}
sein muss.

Der durch die Differentialgleichung~\eqref{buch:hamiltonjacobi:oc:eqn:dgl}
gegebene Zusammenhang von $x(t)$ und $u(t)$ kann als Nebenbedingung 
in der Form
\begin{equation}
G(x,\dot{x}, u)
=
f(x,u) - \dot{x} = 0
\label{buch:hamiltonjacobi:oc:eqn:dglneben}
\end{equation}
betrachtet werden.
Im Gegensatz zu den Problemen, die in
Abschnitt~\ref{buch:nebenbedingungen:lagrangemult:subsection:nebenbedingungen}
untersucht wurden, hat die
Nebenbedingung~\eqref{buch:hamiltonjacobi:oc:eqn:dglneben}
nicht die der Form eines Integrals.
Es reicht also nicht, eine zusätzliche Vektorvariable $\lambda\in\mathbb{R}^n$
einzuführen und damit ein Funktional mit einer Lagrange-Funktion der Form
\[
L(x,u) - \lambda \cdot G(x,\dot{x},u)
\]
zu minimieren, womit
Abschnitt~\ref{buch:nebenbedingungen:lagrangemult:subsection:nebenbedingungen}
erfolgreich gewesen war.

Als Erweiterung bietet sich an, die Variable $\lambda$ durch eine
Funktion $p(t)$ zu ersetzen.
So entsteht ein neues Funktional
\[
F
\colon
\mathbb{R}^n\times\mathbb{R}^m\times\mathbb{R}^n
\to\mathbb{R}
:
(x,u,p)
\mapsto
F(x,u,p)
=
L(x,u) + p\cdot (f(x,u) - \dot{x}),
\]
für welches jetzt untersucht werden soll, ob sich damit das Problem lösen
lässt.

%
% Die Euler-Lagrange-Differentialgleichung für F
%
\subsubsection{Die Euler-Lagrange-Differentialgleichung für $F$}
Gesucht ist jetzt eine Funktion $q(t)=(x(t),u(t),p(t))$ derart,
dass das Funktional mit der Lagrange-Funktion
\[
F(q,\dot{q})
=
L(x,u) +p\cdot f(x,u) - p\cdot \dot{x}
\]
minimiert.
Die Euler-Lagrange-Differentialgleichung von $F$ ist
\begin{equation}
\frac{\partial F}{\partial q}(q(t),\dot{q}(t))
=
\frac{d}{dt}
\frac{\partial F}{\partial \dot{q}}(q(t),\dot{q}(t)).
\label{buch:hamiltonjacobi:oc:eqn:Feulerlagrange}
\end{equation}
Die partiellen Ableitungen nach $q$ und $\dot{q}$ lassen sich aufteilen
in die Komponenten $x$, $u$ und $p$ von $q$.
Wir berechnen nur die Komponenten für $p$, sie ist
\begin{align}
\frac{\partial F}{\partial p}
&=
f(x,u)
-
\dot{x}
&
\frac{\partial F}{\partial \dot{p}}
&=
0
&&\Rightarrow&
f(x,u)-\dot{x}&=0
\label{buch:hamiltonjacobi:oc:eqn:Fsystemdgl}
\end{align}
Die letzte Gleichung ist die Nebenbedingung, eine Lösung der
Euler-Lagrange-Differential\-gleichung erfüllt also automatisch auch die
Systemdifferentialgleichung~\eqref{buch:hamiltonjacobi:oc:eqn:dgl}.

%
% Die Lösung der optimalen Steuerungsaufgaben
%
\subsubsection{Die Lösung der optimalen Steuerungsaufgaben}
Die Euler-Lagrange-Differentialgleichung zusammen mit geeigneten
Anfangsbedingungen für die gesuchten Funktionen können die
optimale Steuerungsaufgaben lösen, wie der folgende Satz zeigt.

\begin{satz}[Optimale Steuerung, Lagrange-Form]
\label{buch:hamiltonjacobi:oc:satz:optimal-lagrange}
Eine Extremale des Funktionals
\begin{equation}
I(q)
=
\int_{t_0}^{t_1}
F(q(t),\dot{q}(t))
\,dt
+
K(x(t))
\end{equation}
mit der Lagrange-Funktion
\begin{equation}
F(q,\dot{q}) = L(x,u) + p\cdot(f(x,u) - \dot{x})
\label{buch:hamiltonjacobi:oc:optF}
\end{equation}
und den Randbedingungen
\[
x(t_0)=x_0
\qquad\text{und}\qquad
p(t_1)=\frac{\partial K}{\partial x}(x(t_1))
\]
ist eine Lösung der optimale
Steuerungsaufgabe~\ref{buch:hamiltonjacobi:oc:aufgabe}.
\end{satz}

\begin{proof}
Da nach
\eqref{buch:hamiltonjacobi:oc:eqn:Fsystemdgl}
eine Lösung der Euler-Lagrange-Differentialgleichung von $F$ immer
auch die Systemdifferentialgleichung löst, ist 
\begin{equation*}
F(q_*(t),\dot{q}_*(t))
=
L(x_*(t),u_*(t))
+
p_*(t)\cdot (
\underbrace{f(x_*(t),u_*(t))-\dot{x}_*(t)}_{\displaystyle=0})
=
L(x_*(t),u_*(t)).
\end{equation*}
Insbesondere ist auch
\[
\int_{t_0}^{t_1}
F(q_*(t),\dot{q}_*(t))
\,dt
=
\int_{t_0}^{t_1}
L(x_*(t),u_*(t))
\,dt,
\]
Der Wert des Integrals im Funktion ändert also nicht.

Am Intervallende bei $t_1$ sind die Werte von $x_*(t)$ nicht
vorgegeben.
Der Satz~\ref{buch:nebenbedingungen:transversal:satz:randterme}
erklärt, wie der Randterm $K(x(t))$ sich in Randbedingungen
\[
\frac{\partial F}{\partial \dot{q}}(q(t),\dot{q}(t))
+
\frac{\partial K}{\partial q}(q(t_1))
=
0
\]
für $q(t_1)$ umrechnen lässt.
Indem man die Ableitungen nach den Komponenten von $q$ separat betrachtet,
findet man
\begin{align*}
0
&=
\frac{\partial F}{\partial\dot{x}}(q(t_1),\dot{q}(t_1))
+
\frac{\partial K}{\partial x}(q(t_1))
=
-p_*(t_1)
+
\frac{\partial K}{\partial x}(x_*(t_1))
&&\Rightarrow&p_*(t_1)
&=
\frac{\partial K}{\partial x}(x_*(t_1))
\intertext{Dies ist die gesuchte Randbedingung für $p_*(t)$.
Die verbleibenden Komponenten sind}
0
&=
\frac{\partial F}{\partial\dot{u}}(q(t_1),\dot{q}(t_1))
+
\frac{\partial K}{\partial u}(q(t_1))
\\
0
&=
\frac{\partial F}{\partial\dot{p}}(q(t_1),\dot{q}(t_1))
+
\frac{\partial K}{\partial p}(q(t_1)).
\end{align*}
Da die Funktionen auf der rechten Seite nicht von den Variablen
abhängen, nach denen sie abgeleitet werden, sind diese Bedingungen
automatisch erfüllt.
\end{proof}

Die Funktion $F(q,\dot{q})$ hängt nicht von der unabhängigen
Variablen $t$ ab, somit ist die Beltrami-Identität
(Satz~\ref{buch:variation:eulerlagrange:satz:beltrami})
anwendbar.
Sie sagt, dass die Grösse
\begin{align}
F(q,\dot{q})
-
\dot{q}\cdot\frac{\partial F}{\partial\dot{q}}(q,\dot{q})
&=
F(q,\dot{q})
-
\dot{x}\cdot
\underbrace{
\frac{\partial F}{\partial\dot{x}}
}_{\displaystyle=-p}
\mathstrut-
\dot{u}\cdot
\underbrace{
\frac{\partial F}{\partial\dot{u}}
}_{\displaystyle=0}
\mathstrut-
\dot{p}\cdot
\underbrace{
\frac{\partial F}{\partial\dot{p}}
}_{\displaystyle=0}
\notag
\\
&=
L(x,u)+p\cdot f(x,u)-p\cdot\dot{x}
-
\dot{x}\cdot
(-p)
\notag
\\
&=
L(x,u) + p\cdot f(x,u)
\label{buch:hamiltonjacobi:oc:hamilton}
\end{align}
konstant ist.
Diese Funktion spielt daher in der nachfolgenden Konstruktion zur
Lösung der optimalen Steuerungsaufgabe eine grosse Rolle.

%
% Die Hamilton-Differentialgleichungen
%
\subsection{Die Hamilton-Differentialgleichungen
\label{buch:hamiltonjacobi:oc:subsection:hamilton}}
Für eine Lagrange-Funktion $L(x,u)$ haben wir gefunden, dass der
Ausdruck~\eqref{buch:hamiltonjacobi:oc:hamilton} eine besondere
Bedeutung hat.
Wir geben ihm daher einen Namen.

\begin{definition}[Steuerungs-Hamiltonfunktion]
Die Funktion
\[
H
\colon
\mathbb{R}^n\times\mathbb{R}^n\times\mathbb{R}^m
\to
\mathbb{R}
:
(x,p,u)
\mapsto
H(x,p,u)
=
p\cdot f(x,u) + L(x,u)
\]
heisst die {\em Steuerungs-Hamilton-Funktion}
der optimalen Steuerungsaufgabe~\ref{buch:hamiltonjacobi:oc:aufgabe}.
\end{definition}

Der Name rechtfertigt sich dadurch, dass sich aus $H$ analoge
Differentialgleichungen für die Funktionen $x(t)$ und $p(t)$ bilden
lassen.
Damit wird es möglich, auch die Funktion $p(t)$ zu berechnen.
Wenn sich ausserdem eine Bedingung für $u(t)$ finden lässt, kann
die Aufgabe~\ref{buch:hamiltonjacobi:oc:aufgabe}
vollständig gelöst werden.
Eine solche Bedingung wird später im Minimum-Prinzip gefunden.
Als erstes sollen jetzt die Differentialgleichungen konstruiert
werden, die sich aus $H$ ableiten lassen.

%
% Partielle Ableitungen
%
\subsubsection{Partielle Ableitungen}
Zu diesem Zweck sei $q_*(t)=(x_*(t),u_*(t),p_*(t))$ eine Lösung der
Euler-Lagrange-Differen\-tialgleichung
\eqref{buch:hamiltonjacobi:oc:eqn:Feulerlagrange}
für die Lagrange-Funktion $F(q,\dot{q})$.
Als Vorbereitung für die Berechnung der partiellen Ableitungen von $H$
schreiben wir die Euler-Lagrange-Differen\-tialglei\-chungen explizit
für die einzelnen Komponenten von $q$ hin:
\begin{align}
0
&=
\frac{\partial F}{\partial x_k}(x_*(t),u_*(t),p_*(t))
-
\frac{d}{dt}
\frac{\partial F}{\partial \dot{x}_k}(x_*(t),u_*(t),p_*(t))
\notag
\\
&=
\frac{\partial L}{\partial x_k}(x_*(t),u_*(t))
+
p_*(t)\cdot\frac{\partial f}{\partial x_k}(x_*(t),u_*(t))
+
\dot{p}_{*k}
\notag
\\
\Rightarrow\qquad
\dot{p}_*(t)
&=
-\frac{\partial L}{\partial x}(x_*(t),u_*(t))
-
p_*(t)\cdot\frac{\partial f}{\partial x}(x_*(t),u_*(t))
\label{buch:hamiltonjacobi:oc:eqn:Fxabl}
\intertext{Die Variablen $\dot{u}$ und $\dot{p}$ kommen in $F$ nicht
vor, der Zeitableitungsterm kommt daher in den zugehörigen
Euler-Lagrange-Gleichungen nicht vor:}
0
&=
\frac{\partial F}{\partial u_k}(x_*(t),u_*(t),p_*(t))
-
\frac{d}{dt}
\frac{\partial F}{\partial \dot{u}_k}(x_*(t),u_*(t),p_*(t))
\notag
\\
&=
\frac{\partial L}{\partial u_k}(x_*(t),u_*(t))
+
p_*(t)\cdot\frac{\partial f}{\partial u_k}(x_*(t),u_*(t))
\label{buch:hamiltonjacobi:oc:eqn:Fuabl}
\\
0
&=
\frac{\partial F}{\partial p_k}(x_*(t),u_*(t),p_*(t))
-
\frac{d}{dt}
\frac{\partial F}{\partial \dot{p}_k}(x_*(t),u_*(t),p_*(t))
\notag
\\
&=
f_k(x_*(t),u_*(t))-\dot{x}_{*k}(t)
\notag
\\
\Rightarrow\qquad
\dot{x}_*(t)
&=
f(x_*(t),u_*(t)).
\label{buch:hamiltonjacobi:oc:eqn:Fpabl}
\end{align}

Nach diesen Vorbereitungen können jetzt auch die partiellen Ableitungen
von $H$ berechnet werden.
Unter Verwendung von 
\eqref{buch:hamiltonjacobi:oc:eqn:Fxabl},
\eqref{buch:hamiltonjacobi:oc:eqn:Fuabl}
und
\eqref{buch:hamiltonjacobi:oc:eqn:Fpabl}
Folgen die Gleichungen
\begin{equation}
\renewcommand{\arraycolsep}{2pt}
\renewcommand{\arraystretch}{2.0}
\begin{array}{rclcl}
\displaystyle
\frac{\partial H}{\partial x_k}(x_*(t),u_*(t),p_*(t))
&=&
\displaystyle
\frac{\partial L}{\partial x}(x_*(t),u_*(t))
+
p_*(t)\cdot\frac{\partial f}{\partial x_k}(x_*(t),u_*(t))
&=&-\dot{p}_{*k}(t)
\\
\displaystyle
\frac{\partial H}{\partial u_k}(x_*(t),u_*(t),p_*(t))
&=&
\displaystyle
p_*(t)\cdot
\frac{\partial f}{\partial u_k}(x_*(t),u_*(t))
+
\frac{\partial L}{\partial u_k}(x_*(t),u_*(t))
&=&0
\\
\displaystyle
\frac{\partial H}{\partial p_k}(x_*(t),u_*(t),p_*(t))
&=&
f_k(x_*(t),u_*(t))
&=&
\dot{x}_{*k}(t)
\end{array}
\label{buch:hamiltonjacobi:oc:Habl}
\end{equation}

%
% Randbedingungen
%
\subsubsection{Randbedingungen}
Die Anfangsbedingung $x_*(t_0)=x_0$ für $x_*(t)$ ist bereits durch
die Aufgabenstellung gegeben.
Für die Funktion $p_*(t)$ wird eine weitere Randbedingung benötigt,
damit die Differentialgleichungen~\eqref{buch:hamiltonjacobi:oc:Habl}
Beide Funktionen $x_*(t)$ und $p_*(t)$ bestimmen können.
Der Satz~\ref{buch:hamiltonjacobi:oc:satz:optimal-lagrange}
definiert auch die Randbedingung $p_*(t_1)=K(x_*(t_1))$.

%
% Differentialgleichung
%
\subsubsection{Differentialgleichung}
Die Differentialgleichungen~\eqref{buch:hamiltonjacobi:oc:Habl} zusammen
mit den Randbedingungen des vorangegangenen Abschnitts ergeben jetzt
den folgenden Satz.

\begin{satz}[Hamilton-Gleichungen]
\label{buch:hamiltonjacobi:oc:satz:hamilton-gleichungen}
Eine Lösung $(x_*(t),u_*(t),p_*(t))$ der optimalen Steuerungsaufgabe
erfüllt die {\em Hamilton-Differentialgleichungen}
\begin{align*}
\dot{x}_*(t)
&=
\phantom{-}
\frac{\partial H}{\partial p}(x_*(t),u_*(t),p_*(t))
&
x_*(t_0)
&=
x_0
\\
\dot{p}_*(t)
&=
-
\frac{\partial H}{\partial x}(x_*(t),u_*(t),p_*(t)).
&
p_*(t_1)
&=
\frac{\partial K}{\partial x}(x_*(t_1))
\end{align*}
Ausserdem verschwindet die Ableitung nach $u$
\begin{equation}
\frac{\partial H}{\partial u}(x_*(t),u_*(t),p_*(t))=0.
\label{buch:hamiltonjacobi:oc:eqn:ablHu0}
\end{equation}
\end{satz}

Der Satz bestimmt $x_*(t)$ und $p_*(t)$ sobald $u_*(t)$ gegeben ist,
er macht aber ausser der Bedingung, dass die
Ableitung~\eqref{buch:hamiltonjacobi:oc:eqn:ablHu0} verschwindet,
keine Aussage darüber, wie $u_*(t)$ gefunden werden kann.
Ein mögliche Wahl für $u_*(t)$ könnte sein, dass $u_*(t)$ jeweils
als das Extremum der Funktion $u\mapsto H(x_*(t),u,p_*(t))$
gewählt wird.
Dass dies auch die optimale Wahl sein kann, zeigt das Minimum-Prinzip
von Pontryagin, welches im
Abschnitt~\ref{buch:hamiltonjacobi:oc:subsection:minimum}
besprochen werden soll.

%
% Das Minimum-Prinzip
%
\subsection{Das Minimum-Prinzip
\label{buch:hamiltonjacobi:oc:subsection:minimum}}
In Satz~\ref{buch:hamiltonjacobi:oc:satz:hamilton-gleichungen}
und in der daran anschliessenden Diskussion wird angedeutet, dass
wegen der Bedingung~\eqref{buch:hamiltonjacobi:oc:eqn:ablHu0}
die Funktion $u_*(t)$ ein Extremum der Funktion $H$ zu den gegebenen
Werten $x_*(t)$ und $p_*(t)$ sei.
Eine solche Bedingung vervollständigt die Lösung des optimalen
Steuerungsproblems.

\begin{satz}[Pontryagin]
Seien die Funktionen $f(x,u)$ und $L(x,u)$ steteig differenzierbar in 
$x$ und $u$ und sei $K(x)$ stetig differenzierbar in $x$.
Sei die Funktion $u_*\colon[t_0,t_1]\to\mathbb{R}$ eine Lösung des
optimalen Steuerungsproblems Aufgabe~\ref{buch:hamiltonjacobi:oc:aufgabe}
und sei $x_*(t)$ die resultierende optimale Bahnkurve, dann gibt es
eine eindeutig bestimmte Funktion $p_*\colon[t_0,t_1]\to\mathbb{R}$,
So dass $x_*(t),u_*(t),p_*(t)$ die Hamilton-Differentialgleichungen
von Satz~\ref{buch:hamiltonjacobi:oc:satz:hamilton-gleichungen}
erfüllen.
Die Funktion $u_*(t)$ erfüllt
\begin{equation}
u_*(t)
=
\operatorname{argmin}_{u\in\mathbb{R}} H(x_*(t),u,p_*(t)).
\label{buch:hamiltonjacobi:oc:eqn:argminH}
\end{equation}
für alle Stellen $t\in[t_0,t_1]$, an denen $u_*(t)$ stetig ist.
\end{satz}

Dass die Bedingung \eqref{buch:hamiltonjacobi:oc:eqn:argminH} nur
an Stellen gelten muss, an denen $u_*(t)$ stetig ist, lässt zu,
dass die Funktion $u_*$ nicht stetig ist.


